{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1127b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8fcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "legacy=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9563db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"It fills my heart with joy unspeakable to rise in response to the warm and cordial welcome\n",
    "which you have given us. I thank you in the name of the most ancient order of monks in the\n",
    "world; I thank you in the name of the mother of religions; and I thank you in the name of\n",
    "millions and millions of Hindu people of all classes and sects. My thanks, also, to some of the\n",
    "speakers on this platform who, referring to the delegates from the Orient, have told you that\n",
    "these men from far-off nations may well claim the honour of bearing to different lands the\n",
    "idea of toleration. I am proud to belong to a religion which has taught the world both\n",
    "tolerance and universal acceptance. We believe not only in universal toleration, but we accept\n",
    "all religions as true. I am proud to belong to a nation which has sheltered the persecuted and\n",
    "the refugees of all religions and all nations of the earth. I am proud to tell you that we have\n",
    "gathered in our bosom the purest remnant of the Israelites, who came to Southern India and\n",
    "took refuge with us in the very year in which their holy temple was shattered to pieces by\n",
    "Roman tyranny. I am proud to belong to the religion which has sheltered and is\n",
    "still fostering remnant Zoroastrian nation. I will quote to you, brethren, a few lines from a\n",
    "hymn which I remember to have repeated from my earliest boyhood, which is every day\n",
    "repeated by millions of human beings: \"As the different streams having their sources in\n",
    "different places all mingle their water in the sea, so, O Lord, the different paths which\n",
    "men take through different tendencies, various though they appear, crooked or straight, all\n",
    "lead to Thee.\"\"\"\n",
    "max_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a53678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text and encode it as input for the model\n",
    "input_text = \"summarize: \" + text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "293e4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delegates from the Orient have told you that men from far-off nations may well claim the honour of bearing to different lands the idea of toleration. i am proud to belong to a religion which has taught the world both tolerance and universal acceptance.\n"
     ]
    }
   ],
   "source": [
    "summary = model.generate(input_ids, max_length=max_length)\n",
    "summary_text = tokenizer.decode(summary[0], skip_special_tokens=True)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2d1db",
   "metadata": {},
   "source": [
    "So till here we now have a proper working model to summarize a text or transcipt which is given\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb707de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read text from a file\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\Aman Chaturvedi\\Downloads\\notes.txt\"  # Provide the path to your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfa4343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delegates from the Orient have told you that men from far-off nations may well claim the honour of bearing to different lands the idea of toleration. i am proud to belong to a religion which has taught the world both tolerance and universal acceptance.\n"
     ]
    }
   ],
   "source": [
    "text=read_text_from_file\n",
    "summary = model.generate(input_ids, max_length=max_length)\n",
    "summary_text = tokenizer.decode(summary[0], skip_special_tokens=True)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20d9dd",
   "metadata": {},
   "source": [
    "ok next step is to train this model for conversation summary and breakdowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97f28ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\Aman Chaturvedi\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:433: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Hello, how are you? Person 2: I'm doing well too. I couldn't believe they won.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import transformers\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Define the maximum length for the summary\n",
    "max_length = 100\n",
    "\n",
    "# Define the conversation as a list of dialogues\n",
    "conversation = [\n",
    "    \"Person 1: Hello, how are you?\",\n",
    "    \"Person 2: Hi, I'm good thanks. How about you?\",\n",
    "    \"Person 1: I'm doing well too. Did you watch the game last night?\",\n",
    "    \"Person 2: Yes, it was amazing! I couldn't believe they won.\",\n",
    "    \"Person 1: Yeah, it was a nail-biter until the end.\",\n",
    "    \"Person 2: Definitely. We should watch the next game together.\",\n",
    "    \"Person 1: That sounds like a plan!\"\n",
    "]\n",
    "\n",
    "# Concatenate the dialogues into a single text\n",
    "conversation_text = \" \".join(conversation)\n",
    "\n",
    "# Preprocess the text and encode it as input for the model\n",
    "input_text = \"summarize conversation: \" + conversation_text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate a summary\n",
    "summary = model.generate(input_ids, max_length=max_length, num_return_sequences=1, early_stopping=True)\n",
    "\n",
    "# Decode the summary\n",
    "summary_text = tokenizer.decode(summary[0], skip_special_tokens=True)\n",
    "print(summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90350ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
